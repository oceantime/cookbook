#########################################################
# LFM2-350M 本地Docker训练配置（LoRA参数高效微调）
# 修改自 lfm2_350m_lora.yaml，适配Docker Compose环境
#########################################################

seed: 23

# Language Model parameters
model_name: LiquidAI/LFM2-350M
max_seq_length: 2048
system_prompt: |
  You control a web browser through BrowserGym actions.
  You must complete the given web task by interacting with the page.

  Available actions:
  - noop() - Do nothing
  - click(bid) - Click element with BrowserGym ID (the number in brackets)
  - fill(bid, text) - Fill input field with text
  - send_keys(text) - Send keyboard input
  - scroll(direction) - Scroll up/down

  The page structure shows elements as: [bid] element_type 'element_text'
  For example: [13] button 'Click Me!' means bid='13'

  Reply with exactly ONE action on a single line, e.g.:
  click('13')
  fill('42', 'hello world')
  noop()

  Do not include explanations or multiple actions.

# BrowserGym environment (修改为本地Docker容器)
browsergym_url: http://browsergym:8000
dataset_size: 100
default_goal: Complete the web task successfully.

# Training hyperparameters (adjusted for LoRA)
learning_rate: 1.0e-4  # Higher LR suitable for LoRA (fewer trainable params)
warmup_steps: 10

# vLLM inference (针对NVIDIA GB10优化)
per_device_train_batch_size: 1
num_generations: 4
generation_batch_size: 4
max_steps: 100  # 完整训练步数
max_completion_length: 32
use_vllm: true
vllm_mode: "colocate"
vllm_gpu_memory_utilization: 0.15  # Slightly increased to accommodate LoRA adapters

# LoRA configuration (ENABLED - 内存高效)
use_peft: true
lora_r: 8
lora_alpha: 16
lora_dropout: 0.0
lora_bias: "none"
use_rslora: false
lora_target_modules:
  - "q_proj"
  - "k_proj"
  - "v_proj"
  - "o_proj"
  - "gate_proj"
  - "up_proj"
  - "down_proj"

# Experiment tracking (本地TensorBoard)
wandb_enabled: true  # 复用字段名，实际使用TensorBoard
wandb_project_name: "browser-control-local-lora"
logging_steps: 1
push_to_hf: false  # 本地训练不上传
